Loading…New search experience powered by AICollectives™ on Stack Overflow1 month ago                        540 times                                0        from langchain.chains import ConversationalRetrievalChainfrom langchain.memory import ConversationBufferMemoryfrom langchain.vectorstores import DocArrayInMemorySearchfrom langchain.embeddings.openai import OpenAIEmbeddingsfrom langchain.document_loaders import (    UnstructuredWordDocumentLoader,    TextLoader,    UnstructuredPowerPointLoader,)from langchain.tools import Toolfrom langchain.utilities import GoogleSearchAPIWrapperfrom langchain.chat_models import ChatOpenAIimport osimport openaiimport sysfrom dotenv import load_dotenv, find_dotenvsys.path.append('../..')_ = load_dotenv(find_dotenv())  # read local .env filegoogle_api_key = os.environ.get("GOOGLE_API_KEY")google_cse_id = os.environ.get("GOOGLE_CSE_ID")# Initialize OpenAI API keyopenai.api_key = os.environ['OPENAI_API_KEY']# Initialize Langchain environmentos.environ["LANGCHAIN_TRACING_V2"] = "true"os.environ["LANGCHAIN_ENDPOINT"] = "https://api.langchain.plus"os.environ["LANGCHAIN_API_KEY"] = os.environ['LANGCHAIN_API_KEY']os.environ["GOOGLE_API_KEY"] = google_api_keyos.environ["GOOGLE_CSE_ID"] = google_cse_id# Replace with the actual folder pathsfolder_path_docx = "DB\\DB VARIADO\\DOCS"folder_path_txt = "DB\\BLOG-POSTS"folder_path_pptx_1 = "DB\\PPT JUNIO"folder_path_pptx_2 = "DB\\DB VARIADO\\PPTX"# Create a list to store the loaded contentloaded_content = []# Load and process DOCX filesfor file in os.listdir(folder_path_docx):    if file.endswith(".docx"):        file_path = os.path.join(folder_path_docx, file)        loader = UnstructuredWordDocumentLoader(file_path)        docx = loader.load()        loaded_content.extend(docx)# Load and process TXT filesfor file in os.listdir(folder_path_txt):    if file.endswith(".txt"):        file_path = os.path.join(folder_path_txt, file)        loader = TextLoader(file_path, encoding='utf-8')        text = loader.load()        loaded_content.extend(text)# Load and process PPTX files from folder 1for file in os.listdir(folder_path_pptx_1):    if file.endswith(".pptx"):        file_path = os.path.join(folder_path_pptx_1, file)        loader = UnstructuredPowerPointLoader(file_path)        slides_1 = loader.load()        loaded_content.extend(slides_1)# Load and process PPTX files from folder 2for file in os.listdir(folder_path_pptx_2):    if file.endswith(".pptx"):        file_path = os.path.join(folder_path_pptx_2, file)        loader = UnstructuredPowerPointLoader(file_path)        slides_2 = loader.load()        loaded_content.extend(slides_2)# Initialize OpenAI Embeddingsembedding = OpenAIEmbeddings()# Create embeddings for loaded contentembeddings_content = []for one_loaded_content in loaded_content:    embedding_content = embedding.embed_query(one_loaded_content.page_content)    embeddings_content.append(embedding_content)db = DocArrayInMemorySearch.from_documents(loaded_content, embedding)retriever = db.as_retriever(search_type="similarity", search_kwargs={"k": 3})search = GoogleSearchAPIWrapper()def custom_search(query):    internet_results = search.run(query)    print(internet_results)    return internet_resultschain = ConversationalRetrievalChain.from_llm(    llm=ChatOpenAI(model_name="gpt-4", temperature=0),    chain_type="map_reduce",    retriever=retriever,    return_source_documents=True,    return_generated_question=True,)history = []while True:    query = input("Hola, soy Chatbot. ¿Qué te gustaría saber? ")    # Use the custom_search function to get internet search results    internet_results = custom_search(query)    # Combine the custom data and internet search results    combined_results = loaded_content + [internet_results]    # Pass the combined results to the chain    response = chain(        {"question": query, "chat_history": history, "documents": combined_results})    print(response["answer"])    history.append(("system", query))  # user's query    history.append(("assistant", response["answer"]))  # chatbot's response                        Follow                            asked                                         1 Answer                                                Sorted by:                                Highest score (default)                                            Trending (recent votes count more)                                            Date modified (newest first)                                            Date created (oldest first)                                0        query="what is stackoverflow?"internet_results_prior=search.run(query)def custom_search(query):    #internet_results = search.run(query) # comment this line and add the following    internet_results = search.results(query,3) # replace with it, so gets metadata results, 3 means return three results    print(internet_results)    return internet_resultsquery="what is stackoverflow?"internet_results = custom_search(query)[{'title': 'Stack Overflow - Where Developers Learn, Share, & Build Careers', 'link': 'https://stackoverflow.com/', 'snippet': 'Stack Overflow is the largest, most trusted online community for developers to learn, share\u200b \u200btheir programming \u200bknowledge, and build their careers.'}, {'title': 'Stack Overflow - Wikipedia', 'link': 'https://en.wikipedia.org/wiki/Stack_Overflow', 'snippet': 'Stack Overflow is a question-and-answer website for programmers. It is the flagship site of the Stack Exchange Network. It was created in 2008 by Jeff\xa0...'}, {'title': 'What is a stack overflow error?', 'link': 'https://www.techtarget.com/whatis/definition/stack-overflow', 'snippet': 'A stack overflow is a type of buffer overflow error that occurs when a computer program tries to use more memory space in the call stack than has been\xa0...'}]for result in internet_results:    print(result['snippet'])    print("---"*10)Stack Overflow is the largest, most trusted online community for developers to learn, share​ ​their programming ​knowledge, and build their careers.------------------------------Stack Overflow is a question-and-answer website for programmers. It is the flagship site of the Stack Exchange Network. It was created in 2008 by Jeff ...------------------------------A stack overflow is a type of buffer overflow error that occurs when a computer program tries to use more memory space in the call stack than has been ...import os#https://console.cloud.google.com/apis/credentialsos.environ["GOOGLE_CSE_ID"] = "xxx"#https://programmablesearchengine.google.com/controlpanel/createos.environ["GOOGLE_API_KEY"] = "xxx"from langchain.utilities import GoogleSearchAPIWrappersearch = GoogleSearchAPIWrapper()def custom_search(query):    #internet_results = search.run(query) # comment this line and add the following    internet_results = search.results(query,3) # replace with it, so gets metadata results    print(internet_results)    return internet_resultsquery="what is stackoverflow?"internet_results = custom_search(query)for result in internet_results:    print(result['snippet'])    print("---"*10)loaded_content=[]loaded_content=loaded_content + [internet_results_prior]#convert list to list of docsfrom langchain.docstore.document import Documentloaded_content_docs=[]for each_content in loaded_content:    loaded_content_docs.append(Document(page_content=each_content, metadata={"source": "internet"}))from langchain.chains import ConversationalRetrievalChainfrom langchain.vectorstores import DocArrayInMemorySearchfrom langchain.chat_models import ChatOpenAIfrom langchain.embeddings.openai import OpenAIEmbeddings# Initialize OpenAI Embeddingsembedding = OpenAIEmbeddings()vector_db = DocArrayInMemorySearch.from_documents(loaded_content_docs, embedding)retriever = vector_db.as_retriever(search_type="similarity", search_kwargs={"k": 3})history = []chain = ConversationalRetrievalChain.from_llm(    llm=ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0), # did not have access to chat-gpt    chain_type="map_reduce",    retriever=retriever,    return_source_documents=True,    return_generated_question=True,)question="do you know about stackoverflow?"response = chain(        {"question": question, "chat_history": history, "documents": loaded_content_docs})print(response["answer"])                        Follow                            answered                                     Your Answer                                Draft savedDraft discardedSign up or  Sign up using Google                         Sign up using Facebook                         Sign up using Email and Password                        SubmitPost as a guestNameEmailPost as a guestNameEmail                                            Post Your Answer                                                                                    Discard                                        Not the answer you're looking for? Browse other questions tagged  or .                                Related                Subscribe to RSS                                    Question feed                        lang-py                            Accept all cookies                                                    Necessary cookies only                                                    Customize settings                         